{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKSyeIk716Sy",
    "outputId": "5ec0bfc3-e0ce-4436-f2ae-c48055e8f75d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 21:58:26.024637: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rajapaksha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rajapaksha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/rajapaksha/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import random\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rajapaksha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rajapaksha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/rajapaksha/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5nknXn3w25JX"
   },
   "outputs": [],
   "source": [
    "data_file = open('intents.json').read()\n",
    "data = json.loads(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8v5XY8vi3ITE"
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "classes = []\n",
    "data_X = []\n",
    "data_y = []\n",
    "\n",
    "for intent in data[\"intents\"]:\n",
    "  for pattern in intent[\"patterns\"]:\n",
    "    tokens = nltk.word_tokenize(pattern)\n",
    "    words.extend(tokens)\n",
    "    data_X.append(pattern)\n",
    "    data_y.append(intent[\"tag\"]),\n",
    "  if intent[\"tag\"] not in classes:\n",
    "    classes.append(intent[\"tag\"])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = [lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]\n",
    "words = sorted(set(words))\n",
    "classes = sorted(set(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "u8SoIWMf6dMt"
   },
   "outputs": [],
   "source": [
    "training = []\n",
    "out_empty = [0]*len(classes)\n",
    "for idx, doc in enumerate(data_X):\n",
    "  bow = []\n",
    "  text = lemmatizer.lemmatize(doc.lower())\n",
    "  for word in words:\n",
    "    bow.append(1) if word in text else bow.append(0)\n",
    "  output_row = list(out_empty)\n",
    "  output_row[classes.index(data_y[idx])] = 1\n",
    "  training.append([bow, output_row])\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "train_X = np.array(list(training[:,0]))\n",
    "train_Y = np.array(list(training[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iA0Z1UCyZs6J",
    "outputId": "7e996a40-c024-4f1c-d2ba-402bac62e930"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 21:59:17.079836: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               7296      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,812\n",
      "Trainable params: 15,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "2/2 [==============================] - 2s 9ms/step - loss: 1.3856 - accuracy: 0.3509\n",
      "Epoch 2/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1979 - accuracy: 0.5614\n",
      "Epoch 3/150\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0367 - accuracy: 0.5789\n",
      "Epoch 4/150\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9789 - accuracy: 0.5789\n",
      "Epoch 5/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.9267 - accuracy: 0.5789\n",
      "Epoch 6/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.8451 - accuracy: 0.5789\n",
      "Epoch 7/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.8252 - accuracy: 0.6316\n",
      "Epoch 8/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7133 - accuracy: 0.7018\n",
      "Epoch 9/150\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6465 - accuracy: 0.7544\n",
      "Epoch 10/150\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5902 - accuracy: 0.7544\n",
      "Epoch 11/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5339 - accuracy: 0.7719\n",
      "Epoch 12/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4358 - accuracy: 0.8421\n",
      "Epoch 13/150\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4654 - accuracy: 0.8246\n",
      "Epoch 14/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3379 - accuracy: 0.8947\n",
      "Epoch 15/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3144 - accuracy: 0.9298\n",
      "Epoch 16/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2588 - accuracy: 0.9123\n",
      "Epoch 17/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1864 - accuracy: 0.9825\n",
      "Epoch 18/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1701 - accuracy: 0.9649\n",
      "Epoch 19/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1651 - accuracy: 0.9825\n",
      "Epoch 20/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1666 - accuracy: 0.9298\n",
      "Epoch 21/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1424 - accuracy: 0.9474\n",
      "Epoch 22/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1353 - accuracy: 0.9298\n",
      "Epoch 23/150\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1476 - accuracy: 0.9474\n",
      "Epoch 24/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1427 - accuracy: 0.9298\n",
      "Epoch 25/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1477 - accuracy: 0.9298\n",
      "Epoch 26/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0799 - accuracy: 0.9474\n",
      "Epoch 27/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2007 - accuracy: 0.9123\n",
      "Epoch 28/150\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0967 - accuracy: 0.9649\n",
      "Epoch 29/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0942 - accuracy: 0.9649\n",
      "Epoch 30/150\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0768 - accuracy: 0.9649\n",
      "Epoch 31/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0809 - accuracy: 0.9649\n",
      "Epoch 32/150\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1256 - accuracy: 0.9474\n",
      "Epoch 33/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1321 - accuracy: 0.9649\n",
      "Epoch 34/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1069 - accuracy: 0.9649\n",
      "Epoch 35/150\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0960 - accuracy: 0.9825\n",
      "Epoch 36/150\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1352 - accuracy: 0.9298\n",
      "Epoch 37/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0829 - accuracy: 0.9474\n",
      "Epoch 38/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0459 - accuracy: 0.9649\n",
      "Epoch 39/150\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0721 - accuracy: 0.9649\n",
      "Epoch 40/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0804 - accuracy: 0.9649\n",
      "Epoch 41/150\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1236 - accuracy: 0.9298\n",
      "Epoch 42/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0485 - accuracy: 0.9825\n",
      "Epoch 43/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0860 - accuracy: 0.9474\n",
      "Epoch 44/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1048 - accuracy: 0.9474\n",
      "Epoch 45/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0837 - accuracy: 0.9474\n",
      "Epoch 46/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0654 - accuracy: 0.9825\n",
      "Epoch 47/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0882 - accuracy: 0.9649\n",
      "Epoch 48/150\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0499 - accuracy: 0.9825\n",
      "Epoch 49/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0545 - accuracy: 0.9474\n",
      "Epoch 50/150\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0387 - accuracy: 0.9825\n",
      "Epoch 51/150\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0926 - accuracy: 0.9474\n",
      "Epoch 52/150\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0686 - accuracy: 0.9474\n",
      "Epoch 53/150\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0388 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1439 - accuracy: 0.9474\n",
      "Epoch 55/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0626 - accuracy: 0.9825\n",
      "Epoch 56/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0964 - accuracy: 0.9649\n",
      "Epoch 57/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0617 - accuracy: 0.9825\n",
      "Epoch 58/150\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0513 - accuracy: 0.9825\n",
      "Epoch 59/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0645 - accuracy: 0.9825\n",
      "Epoch 60/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0778 - accuracy: 0.9649\n",
      "Epoch 61/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1074 - accuracy: 0.9474\n",
      "Epoch 62/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0419 - accuracy: 0.9825\n",
      "Epoch 63/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0664 - accuracy: 0.9825\n",
      "Epoch 64/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1342 - accuracy: 0.9649\n",
      "Epoch 65/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0779 - accuracy: 0.9298\n",
      "Epoch 66/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1190 - accuracy: 0.9298\n",
      "Epoch 67/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0812 - accuracy: 0.9474\n",
      "Epoch 68/150\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.9649\n",
      "Epoch 69/150\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0804 - accuracy: 0.9474\n",
      "Epoch 70/150\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0623 - accuracy: 0.9649\n",
      "Epoch 71/150\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0508 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1009 - accuracy: 0.9298\n",
      "Epoch 73/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0365 - accuracy: 0.9825\n",
      "Epoch 74/150\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0330 - accuracy: 0.9825\n",
      "Epoch 75/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0605 - accuracy: 0.9474\n",
      "Epoch 76/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0559 - accuracy: 0.9825\n",
      "Epoch 77/150\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0783 - accuracy: 0.9474\n",
      "Epoch 78/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0733 - accuracy: 0.9649\n",
      "Epoch 79/150\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0631 - accuracy: 0.9474\n",
      "Epoch 80/150\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0553 - accuracy: 0.9825\n",
      "Epoch 81/150\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0654 - accuracy: 0.9825\n",
      "Epoch 82/150\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0802 - accuracy: 0.9474\n",
      "Epoch 83/150\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0337 - accuracy: 0.9825\n",
      "Epoch 84/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0951 - accuracy: 0.9649\n",
      "Epoch 85/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0523 - accuracy: 0.9649\n",
      "Epoch 86/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0383 - accuracy: 0.9825\n",
      "Epoch 87/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0769 - accuracy: 0.9474\n",
      "Epoch 89/150\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0490 - accuracy: 0.9649\n",
      "Epoch 90/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0845 - accuracy: 0.9474\n",
      "Epoch 91/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1079 - accuracy: 0.9474\n",
      "Epoch 92/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0928 - accuracy: 0.9474\n",
      "Epoch 93/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0561 - accuracy: 0.9649\n",
      "Epoch 94/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0579 - accuracy: 0.9825\n",
      "Epoch 95/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0904 - accuracy: 0.9649\n",
      "Epoch 96/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0549 - accuracy: 0.9825\n",
      "Epoch 97/150\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0552 - accuracy: 0.9649\n",
      "Epoch 98/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0363 - accuracy: 0.9825\n",
      "Epoch 99/150\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0470 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0520 - accuracy: 0.9649\n",
      "Epoch 102/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0457 - accuracy: 0.9825\n",
      "Epoch 103/150\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0556 - accuracy: 0.9825\n",
      "Epoch 104/150\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0552 - accuracy: 0.9649\n",
      "Epoch 105/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0810 - accuracy: 0.9298\n",
      "Epoch 106/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0521 - accuracy: 0.9649\n",
      "Epoch 107/150\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0924 - accuracy: 0.9298\n",
      "Epoch 108/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0619 - accuracy: 0.9649\n",
      "Epoch 109/150\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0480 - accuracy: 0.9649\n",
      "Epoch 110/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0462 - accuracy: 0.9649\n",
      "Epoch 111/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0484 - accuracy: 0.9825\n",
      "Epoch 112/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0865 - accuracy: 0.9298\n",
      "Epoch 113/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1064 - accuracy: 0.9298\n",
      "Epoch 114/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0368 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0513 - accuracy: 0.9649\n",
      "Epoch 116/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0670 - accuracy: 0.9474\n",
      "Epoch 117/150\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0758 - accuracy: 0.9474\n",
      "Epoch 118/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0619 - accuracy: 0.9825\n",
      "Epoch 119/150\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9649\n",
      "Epoch 120/150\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0714 - accuracy: 0.9649\n",
      "Epoch 121/150\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0310 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0921 - accuracy: 0.9474\n",
      "Epoch 123/150\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0596 - accuracy: 0.9474\n",
      "Epoch 124/150\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0747 - accuracy: 0.9474\n",
      "Epoch 125/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0464 - accuracy: 0.9825\n",
      "Epoch 126/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0470 - accuracy: 0.9825\n",
      "Epoch 127/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0657 - accuracy: 0.9649\n",
      "Epoch 128/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0698 - accuracy: 0.9649\n",
      "Epoch 129/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0619 - accuracy: 0.9649\n",
      "Epoch 130/150\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0568 - accuracy: 0.9649\n",
      "Epoch 131/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0875 - accuracy: 0.9474\n",
      "Epoch 132/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0332 - accuracy: 0.9825\n",
      "Epoch 133/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0561 - accuracy: 0.9649\n",
      "Epoch 134/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0748 - accuracy: 0.9649\n",
      "Epoch 135/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0433 - accuracy: 0.9825\n",
      "Epoch 136/150\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0644 - accuracy: 0.9649\n",
      "Epoch 137/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0863 - accuracy: 0.9474\n",
      "Epoch 138/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0653 - accuracy: 0.9474\n",
      "Epoch 139/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0609 - accuracy: 0.9298\n",
      "Epoch 140/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1164 - accuracy: 0.9474\n",
      "Epoch 141/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0577 - accuracy: 0.9474\n",
      "Epoch 142/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0782 - accuracy: 0.9298\n",
      "Epoch 143/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0503 - accuracy: 0.9649\n",
      "Epoch 144/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0460 - accuracy: 0.9649\n",
      "Epoch 145/150\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0762 - accuracy: 0.9474\n",
      "Epoch 146/150\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0548 - accuracy: 0.9825\n",
      "Epoch 147/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0621 - accuracy: 0.9825\n",
      "Epoch 148/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0597 - accuracy: 0.9825\n",
      "Epoch 149/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0588 - accuracy: 0.9649\n",
      "Epoch 150/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0489 - accuracy: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdba1835c30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = (len(train_X[0]),), activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_Y[0]), activation = \"softmax\"))\n",
    "adam = tf.keras.optimizers.legacy.Adam(learning_rate = 0.01, decay = 1e-6)\n",
    "model.compile(loss = \"categorical_crossentropy\",\n",
    "              optimizer = adam,\n",
    "              metrics = [\"accuracy\"]\n",
    "              )\n",
    "print(model.summary())\n",
    "model.fit(x=train_X, y=train_Y, epochs = 150, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fGTQmlC_9Q8A"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  tokens = nltk.word_tokenize(text)\n",
    "  tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "  return tokens\n",
    "\n",
    "def bag_of_words(text, vocab):\n",
    "  tokens = clean_text(text)\n",
    "  bow = [0]*len(vocab)\n",
    "  for w in tokens:\n",
    "    for idx, word in enumerate(vocab):\n",
    "      if word == w:\n",
    "        bow[idx] = 1\n",
    "  return np.array(bow)\n",
    "\n",
    "def pred_class(text, vocab, labels):\n",
    "  bow = bag_of_words(text, vocab)\n",
    "  result = model.predict(np.array([bow]))[0]\n",
    "  thresh = 0.5\n",
    "  y_pred = [[indx, res] for indx, res in enumerate(result) if res > thresh]\n",
    "  y_pred.sort(key=lambda x: x[1], reverse = True)\n",
    "  return_list = []\n",
    "  for r in y_pred:\n",
    "    return_list.append(labels[r[0]])\n",
    "    return return_list\n",
    "  \n",
    "def get_response(intents_list, intents_json):\n",
    "  if not isinstance(intents_list, list):\n",
    "    intents_list = []\n",
    "\n",
    "  if len(intents_list) == 0:\n",
    "    result = \"Sorry! I don't understand.\"\n",
    "  else:\n",
    "    result = intents_list[0]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "epDQs8cF9axz",
    "outputId": "392de62f-2b70-49ca-f71e-42743d81cbf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Address already in use\n",
      "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n",
      "On macOS, try disabling the 'AirPlay Receiver' service from System Preferences -> Sharing.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/werkzeug/serving.py:911\u001b[0m, in \u001b[0;36mprepare_socket\u001b[0;34m(hostname, port)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 911\u001b[0m     s\u001b[39m.\u001b[39;49mbind(server_address)\n\u001b[1;32m    912\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 48] Address already in use",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[12], line 14\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 14\u001b[0m     app\u001b[39m.\u001b[39;49mrun(debug\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, use_reloader\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/flask/app.py:1188\u001b[0m, in \u001b[0;36mFlask.run\u001b[0;34m(self, host, port, debug, load_dotenv, **options)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1188\u001b[0m     run_simple(t\u001b[39m.\u001b[39;49mcast(\u001b[39mstr\u001b[39;49m, host), port, \u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m   1189\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1190\u001b[0m     \u001b[39m# reset the first request information if the development server\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     \u001b[39m# reset normally.  This makes it possible to restart the server\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m     \u001b[39m# without reloader and that stuff from an interactive shell.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/werkzeug/serving.py:1062\u001b[0m, in \u001b[0;36mrun_simple\u001b[0;34m(hostname, port, application, use_reloader, use_debugger, use_evalex, extra_files, exclude_patterns, reloader_interval, reloader_type, threaded, processes, request_handler, static_files, passthrough_errors, ssl_context)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_running_from_reloader():\n\u001b[0;32m-> 1062\u001b[0m     s \u001b[39m=\u001b[39m prepare_socket(hostname, port)\n\u001b[1;32m   1063\u001b[0m     fd \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mfileno()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/werkzeug/serving.py:930\u001b[0m, in \u001b[0;36mprepare_socket\u001b[0;34m(hostname, port)\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[39mprint\u001b[39m(\n\u001b[1;32m    925\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mOn macOS, try disabling the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mAirPlay Receiver\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    926\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m service from System Preferences -> Sharing.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    927\u001b[0m                 file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    928\u001b[0m             )\n\u001b[0;32m--> 930\u001b[0m     sys\u001b[39m.\u001b[39;49mexit(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    932\u001b[0m s\u001b[39m.\u001b[39mlisten(LISTEN_QUEUE)\n",
      "\u001b[0;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2047\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[1;32m   2045\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2046\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[0;32m-> 2047\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[1;32m   2048\u001b[0m                                                      value))\n\u001b[1;32m   2049\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2051\u001b[0m         \u001b[39m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[1;32m   2052\u001b[0m         \u001b[39m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[1;32m   2053\u001b[0m         \u001b[39m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/ultratb.py:585\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[1;32m    578\u001b[0m     \u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \n\u001b[1;32m    580\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/ultratb.py:452\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    449\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[1;32m    450\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    451\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 452\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m    453\u001b[0m             etype, evalue, (etb, chained_exc_ids),\n\u001b[1;32m    454\u001b[0m             chained_exceptions_tb_offset, context)\n\u001b[1;32m    455\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[1;32m    456\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[1;32m    458\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/ultratb.py:1118\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1117\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m tb\n\u001b[0;32m-> 1118\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m   1119\u001b[0m     \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/ultratb.py:1012\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1009\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[1;32m   1010\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[1;32m   1011\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m   1013\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1015\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   1016\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/ultratb.py:865\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[1;32m    857\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    858\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    862\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[1;32m    863\u001b[0m ):\n\u001b[1;32m    864\u001b[0m     \u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m    866\u001b[0m                                                            tb_offset)\n\u001b[1;32m    868\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m    869\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/ultratb.py:799\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[1;32m    797\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(etype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[1;32m    798\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 799\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[1;32m    800\u001b[0m )\n\u001b[1;32m    802\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[1;32m    803\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/ultratb.py:854\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    848\u001b[0m     formatter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    849\u001b[0m options \u001b[39m=\u001b[39m stack_data\u001b[39m.\u001b[39mOptions(\n\u001b[1;32m    850\u001b[0m     before\u001b[39m=\u001b[39mbefore,\n\u001b[1;32m    851\u001b[0m     after\u001b[39m=\u001b[39mafter,\n\u001b[1;32m    852\u001b[0m     pygments_formatter\u001b[39m=\u001b[39mformatter,\n\u001b[1;32m    853\u001b[0m )\n\u001b[0;32m--> 854\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(stack_data\u001b[39m.\u001b[39;49mFrameInfo\u001b[39m.\u001b[39;49mstack_data(etb, options\u001b[39m=\u001b[39;49moptions))[tb_offset:]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/stack_data/core.py:546\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[0;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    531\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstack_data\u001b[39m(\n\u001b[1;32m    532\u001b[0m         \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m         collapse_repeated_frames: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    537\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[\u001b[39m'\u001b[39m\u001b[39mFrameInfo\u001b[39m\u001b[39m'\u001b[39m, RepeatedFrames]]:\n\u001b[1;32m    538\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[39m    An iterator of FrameInfo and RepeatedFrames objects representing\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39m    a full traceback or stack. Similar consecutive frames are collapsed into RepeatedFrames\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[39m    and optionally an Options object to configure.\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 546\u001b[0m     stack \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(iter_stack(frame_or_tb))\n\u001b[1;32m    548\u001b[0m     \u001b[39m# Reverse the stack from a frame so that it's in the same order\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     \u001b[39m# as the order from a traceback, which is the order of a printed\u001b[39;00m\n\u001b[1;32m    550\u001b[0m     \u001b[39m# traceback when read top to bottom (most recent call last)\u001b[39;00m\n\u001b[1;32m    551\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/stack_data/utils.py:98\u001b[0m, in \u001b[0;36miter_stack\u001b[0;34m(frame_or_tb)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mwhile\u001b[39;00m frame_or_tb:\n\u001b[1;32m     97\u001b[0m     \u001b[39myield\u001b[39;00m frame_or_tb\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n\u001b[1;32m     99\u001b[0m         frame_or_tb \u001b[39m=\u001b[39m frame_or_tb\u001b[39m.\u001b[39mf_back\n\u001b[1;32m    100\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/stack_data/utils.py:91\u001b[0m, in \u001b[0;36mis_frame\u001b[0;34m(frame_or_tb)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_frame\u001b[39m(frame_or_tb: Union[FrameType, TracebackType]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[0;32m---> 91\u001b[0m     assert_(\u001b[39misinstance\u001b[39;49m(frame_or_tb, (types\u001b[39m.\u001b[39;49mFrameType, types\u001b[39m.\u001b[39;49mTracebackType)))\n\u001b[1;32m     92\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(frame_or_tb, (types\u001b[39m.\u001b[39mFrameType,))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/stack_data/utils.py:172\u001b[0m, in \u001b[0;36massert_\u001b[0;34m(condition, error)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(error, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    171\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mAssertionError\u001b[39;00m(error)\n\u001b[0;32m--> 172\u001b[0m \u001b[39mraise\u001b[39;00m error\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route('/search', methods=['POST'])\n",
    "def chat():\n",
    "    message = request.json['search']\n",
    "    intents = pred_class(message, words, classes)\n",
    "    result = get_response(intents, data)\n",
    "    response = jsonify({'response': result})\n",
    "    response.headers.add('Access-Control-Allow-Origin', '*')\n",
    "    return response\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
